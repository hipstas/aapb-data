{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MONGODB Quick Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment these lines to load a db into Mongo.\n",
    "\n",
    "# !cd /Volumes/McLaughlin-6TB-1/Dropbox/Sci-Hub_Analaysis_Project/\n",
    "\n",
    "# !mongoimport --db crossref --collection dois --drop --file DOI_Metadata_from_Crossref_US_filtered-subset_w-some-missing.txt\n",
    "\n",
    "# !mongoimport --db crossref --collection dois --drop --file /Users/mclaugh/Desktop/DOI_Metadata_master_list_1.txt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76421982\n",
      "7A4E8DF4\n",
      "762AE684\n",
      "79C1DF51\n",
      "78255968\n",
      "855BB04E\n",
      "7B715100\n",
      "024E9304\n",
      "78A708D5\n",
      "7B6CC598\n",
      "7D3E2747\n",
      "7AF2FAC8\n",
      "7664D144\n",
      "7BC48C49\n",
      "840F2704\n",
      "775D4441\n",
      "80352E98\n",
      "7A30D197\n",
      "753BD7DA\n",
      "75490B6D\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DICTIONARY OF DOIS to Microsoft Academic Graph IDs\n",
    "\n",
    "pathname=\"/Users/mclaugh/Desktop/DOI_lowercase_to_MAG_ID_US_SUBSET.txt\"\n",
    "lines=open(pathname).read().splitlines()\n",
    "\n",
    "mag_dois_subset=[line.split('\\t')[0] for line in lines]\n",
    "\n",
    "\n",
    "\n",
    "mag_doi_dict={}\n",
    "\n",
    "for doi in mag_dois_subset:\n",
    "\tmag_doi_dict[doi]=[]\n",
    "\n",
    "\n",
    "mag_dois_subset_table=[line.split('\\t') for line in lines]\n",
    "\n",
    "\n",
    "#mapping doi to keyword code\n",
    "for row_pair in mag_dois_subset_table:\n",
    "\tdoi=row_pair[0]\n",
    "\tcode=row_pair[1]\n",
    "\tmag_doi_dict[doi]=code\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "dois=random.sample(mag_dois_subset,10)\n",
    "\n",
    "for doi in dois:\n",
    "\tprint mag_doi_dict[doi]\n",
    "\n",
    "\n",
    "def doi_to_mag_id(doi):\n",
    "    try: return mag_doi_dict[doi.lower()]\n",
    "    except: return \"\"\n",
    "\n",
    "\n",
    "    \n",
    "dois=random.sample(mag_dois_subset,10)+range(10)\n",
    "    \n",
    "for doi in dois:\n",
    "\tprint doi_to_mag_id(doi)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anchorage', 'AK', '61.2180556', '-149.9002778', '']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csv_path=\"/Users/mclaugh/Google Drive/Sci-Hub_ACRL/US-Cities-in-SH-Logs_hand-completed.csv\"\n",
    "\n",
    "geo_sheet=[]\n",
    "\n",
    "with open(csv_path,'rU') as fi:\n",
    "    mydata = csv.reader(fi)\n",
    "    for row in mydata:\n",
    "        geo_sheet.append(row)\n",
    "\n",
    "print geo_sheet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'KS'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_to_state_dict={}\n",
    "\n",
    "for row in geo_sheet:\n",
    "    key=row[2]+\",\"+row[3]\n",
    "    coords_to_state_dict[key]=row[1]\n",
    "\n",
    "\n",
    "print coords_to_state_dict[\"38.9071923,-77.0368707\"]\n",
    "\n",
    "def coords_to_state(coords):\n",
    "    try: return coords_to_state_dict[coords]\n",
    "    except: return \"\"\n",
    "\n",
    "coords_to_state(\"37.9389063,-97.0197557\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go to the terminal and launch the MongoDB shell.\n",
    "\n",
    "    mongo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in mongo shell\n",
    "\n",
    "    use crossref\n",
    "\n",
    "\n",
    "#### Search by DOI\n",
    "\n",
    "    db.dois.find( {'DOI': '10.1061/(asce)0733-9364(1996)122:2(165)'} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'DOI': u'10.2138/rmg.2005.58.7',\n",
      " u'ISSN': [u'1529-6466'],\n",
      " u'URL': u'http://dx.doi.org/10.2138/rmg.2005.58.7',\n",
      " u'_id': ObjectId('57e1aded2c6f69540cee3dd3'),\n",
      " u'author': [{u'affiliation': [], u'family': u'Shuster', u'given': u'D. L.'}],\n",
      " u'container-title': [u'Reviews in Mineralogy and Geochemistry'],\n",
      " u'content-domain': {u'crossmark-restriction': False, u'domain': []},\n",
      " u'created': {u'date-parts': [[2005, 12, 1]],\n",
      "              u'date-time': u'2005-12-01T01:07:14Z',\n",
      "              u'timestamp': 1133399234000L},\n",
      " u'deposited': {u'date-parts': [[2011, 7, 21]],\n",
      "                u'date-time': u'2011-07-21T18:32:35Z',\n",
      "                u'timestamp': 1311273155000L},\n",
      " u'indexed': {u'date-parts': [[2015, 12, 26]],\n",
      "              u'date-time': u'2015-12-26T09:20:04Z',\n",
      "              u'timestamp': 1451121604863L},\n",
      " u'issue': u'1',\n",
      " u'issued': {u'date-parts': [[2005, 1, 1]]},\n",
      " u'member': u'http://id.crossref.org/member/859',\n",
      " u'original-title': [],\n",
      " u'page': u'181-203',\n",
      " u'prefix': u'http://id.crossref.org/prefix/10.2138',\n",
      " u'published-print': {u'date-parts': [[2005, 1, 1]]},\n",
      " u'publisher': u'GeoScienceWorld',\n",
      " u'reference-count': 0,\n",
      " u'score': 1.0,\n",
      " u'short-container-title': [],\n",
      " u'short-title': [],\n",
      " u'source': u'CrossRef',\n",
      " u'subject': [u'Geochemistry and Petrology'],\n",
      " u'subtitle': [],\n",
      " u'title': [u'4He/3He Thermochronometry: Theory, Practice, and Potential Complications'],\n",
      " u'type': u'journal-article',\n",
      " u'volume': u'58'}\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "\n",
    "db = client.crossref\n",
    "cursor = db.dois.find()\n",
    "\n",
    "cursor = db.dois.find( {'DOI': '10.2138/rmg.2005.58.7'})\n",
    "\n",
    "for item in cursor:\n",
    "    pprint(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Takes a DOI and returns a list of matching records.\n",
    "\n",
    "def doi_search(term):\n",
    "\tcursor = db.dois.find( {'DOI': term.lower()})\n",
    "\titems=[item for item in cursor]\n",
    "\treturn items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_path=\"/Users/mclaugh/Google Drive/Sci-Hub_ACRL/Sci-Hub-Logs_United-States.csv\"\n",
    "\n",
    "meta_sheet=[]\n",
    "\n",
    "with open(csv_path,'rU') as fi:\n",
    "    mydata = csv.reader(fi)\n",
    "    for row in mydata:\n",
    "        meta_sheet.append(row)\n",
    "\n",
    "# meta_sheet=meta_sheet[:50] # uncomment for testing with a smaller table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'doi', 'IP_code', 'country', 'city', 'state', 'latitude', 'longitude', 'prefix', 'publisher', 'venue', 'title', 'pub_format', 'subjects', 'date', 'url', 'MAG_ID']\n"
     ]
    }
   ],
   "source": [
    "columns=meta_sheet[0] # saving copy of column names\n",
    "meta_sheet=meta_sheet[1:] # removing columns names from sheet\n",
    "new_columns=columns[:5]+[\"state\"]+columns[6:9]+[\"publisher\",\"venue\",\"title\",\"pub_format\",\"subjects\",\"date\",\"url\",\"MAG_ID\"]\n",
    "print new_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########CONTINUING AFTER A BREAK\n",
    "#meta_sheet2=meta_sheet[695348:]\n",
    "#meta_sheet=meta_sheet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'doi', 'IP_code', 'country', 'city', 'state', 'latitude', 'longitude', 'prefix', 'publisher', 'venue', 'title', 'pub_format', 'subjects', 'date', 'url', 'MAG_ID']\n"
     ]
    }
   ],
   "source": [
    "print new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "########## SEARCHING FOR SHORT LIST OF DOIS\n",
    "\n",
    "meta_sheet_2=[]\n",
    "\n",
    "extra_dois=[\"10.2138/rmg.2005.58.7\",\"10.1007/s10803-004-5283-1\",\"10.1177/1090198108328328\",\"10.3111/13696998.2015.1079530\",\"10.1016/0020-7403(90)90148-c\",\"10.1016/j.dld.2013.06.007\",\"10.1021/jf0616098\"]\n",
    "print len(extra_dois)\n",
    "\n",
    "for row in meta_sheet:\n",
    "    if row[1] in extra_dois:\n",
    "        meta_sheet_2.append(row)\n",
    "\n",
    "print len(meta_sheet_2)\n",
    "\n",
    "meta_sheet=meta_sheet_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 date\n",
      "1 doi\n",
      "2 IP_code\n",
      "3 country\n",
      "4 city\n",
      "5 state\n",
      "6 latitude\n",
      "7 longitude\n",
      "8 prefix\n",
      "9 publisher\n",
      "10 venue\n",
      "11 title\n",
      "12 pub_format\n",
      "13 subjects\n",
      "14 date\n",
      "15 url\n",
      "16 MAG_ID\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_columns)):\n",
    "    print str(i)+' '+new_columns[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015-09-01 00:03:35', '10.1016/b978-0-12-386897-8.00003-6', '56ed2b70f04f6', 'United States', 'Fremont', '37.5482697,-121.9885719', '37.5482697', '-121.9885719', '10.1016']\n"
     ]
    }
   ],
   "source": [
    "print meta_sheet[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_new_fields(row):\n",
    "    meta_dict={}\n",
    "    row[1]=row[1].lower()\n",
    "    try:\n",
    "        records=doi_search(row[1]) ## row[1] is the DOI\n",
    "        if len(records)>0:\n",
    "            meta_dict=records[0]\n",
    "        else: return row[:5]+[coords_to_state(row[5])]+row[6:9]+['','','','','','','',doi_to_mag_id(row[1])]\n",
    "    except: return row[:5]+[coords_to_state(row[5])]+row[6:9]+['','','','','','','',doi_to_mag_id(row[1])]\n",
    "    try: publisher=meta_dict['publisher']\n",
    "    except: publisher=''\n",
    "    try: venue=max(meta_dict['container-title'], key=len) ## Chooses longest option for journal title\n",
    "    except: venue=''\n",
    "    try: title=meta_dict['title'][0]\n",
    "    except: title=''\n",
    "    try: pub_format=meta_dict['type']\n",
    "    except: pub_format=''\n",
    "    try: subjects=\"|\".join(meta_dict['subject'])\n",
    "    except: subjects=''\n",
    "    try: date=str(meta_dict['issued']['date-parts'][0])[1:-1] ## May leave off later dates.\n",
    "    except: date=''\n",
    "    try: url=str(meta_dict['URL'])\n",
    "    except: url=''\n",
    "    return row[:5]+[coords_to_state(row[5])]+row[6:9]+[publisher,venue,title,pub_format,subjects,date,url,doi_to_mag_id(row[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cchardet\n",
    "from unidecode import unidecode\n",
    "\n",
    "def sanitize(text):\n",
    "    if text==None: return \"\"\n",
    "    try: return unidecode(text.decode('utf-8')).strip().replace('\\t',' ').replace('\\n',' ').replace('\\r','')\n",
    "    except:\n",
    "        try: return unidecode(text.encode('utf-8').decode('utf-8')).strip().replace('\\t',' ').replace('\\n',' ').replace('\\r','')\n",
    "        except:       \n",
    "            encoding=cchardet.detect(text)['encoding']\n",
    "            text2=text.strip().replace('\\t',' ').replace('\\n',' ').replace('\\r','')\n",
    "            while \"  \" in text2:\n",
    "                text2=text2.replace(\"  \",\" \")\n",
    "            decoded=text2.decode(encoding)\n",
    "            try: return unidecode(decoded)\n",
    "            except:\n",
    "                encoded=decoded.encode('utf-8')\n",
    "                return unidecode(encoded)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def row_to_string(row):\n",
    "    row2=[sanitize(item) for item in row]\n",
    "    return unidecode(\"\\t\".join(row2)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##testing sanitizer; returns lines that still cause problems\n",
    "\n",
    "\n",
    "pathname=\"/Volumes/McLaughlin-6TB-1/Dropbox/trouble_strings.txt\"\n",
    "naughty_strings=open(pathname).read().splitlines()\n",
    "\n",
    "temp=[]\n",
    "\n",
    "for line in naughty_strings:\n",
    "    try: temp.append(sanitize(line))\n",
    "    except: print line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-29 23:59:25\t10.1177/1090198108328328\t56ed2b0ec5e8d\tUnited States\tSan Gabriel\t34.0961111,-118.1058333\t34.0961111\t-118.1058333\t10.1177\n",
      "\n",
      "2016-02-29 23:59:22\t10.1007/s10803-004-5283-1\t56ed2c078f216\tUnited States\t\t40.5795317,-74.1502007\t40.5795317\t-74.1502007\t10.1007\n",
      "\n",
      "2016-03-01 00:00:00\t10.1021/jf0616098\t56ed2b37b6da5\tUnited States\tWeldon Spring\t38.713386,-90.6892929\t38.713386\t-90.6892929\t10.1021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "rows=random.sample(meta_sheet,3)\n",
    "\n",
    "for row in rows:\n",
    "    #pprint(add_new_fields(row))\n",
    "    print row_to_string(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# The big final batch run:\n",
    "\n",
    "\n",
    "dir_path=\"/Users/mclaugh/Desktop/\"\n",
    "\n",
    "fo=open(dir_path+\"Bohannon_table_plus_Crossref_metadata_pt-x.tsv\",'w')\n",
    "\n",
    "\n",
    "counter=0\n",
    "\n",
    "for row in meta_sheet:\n",
    "    #print row\n",
    "    #print add_new_fields(row)\n",
    "    fo.write(row_to_string(add_new_fields(row)))\n",
    "    if (counter<40)|(counter%5000==0): print counter\n",
    "    counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you need the 'unicodecsv' Python module.\n",
    "\n",
    "# !pip install --user -U unicodecsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#import unicodecsv\n",
    "\n",
    "#dir_path=\"/Users/mclaugh/Desktop/\"\n",
    "\n",
    "#with open(dir_path+\"expanded-table.csv\",'w') as fo:\n",
    "    #a = unicodecsv.writer(fo, encoding='utf-8')\n",
    "    #a.writerow(new_columns)\n",
    "    #a.writerows(new_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
