{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import array\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from pyAudioAnalysis import audioTrainTest as aT\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import get_array_type\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(999)\n",
    "\n",
    "os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton, Bill\n",
      "Clinton_Bill\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Enter Speaker Name Here ##\n",
    "#############################\n",
    "\n",
    "speaker=\"Clinton, Bill\"\n",
    "\n",
    "#############################\n",
    "\n",
    "last_name = speaker.split(', ')[0]+'_Bill'\n",
    "\n",
    "print(speaker)\n",
    "print(last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading dictionary of applause classification values\n",
    "\n",
    "applause_labels_dir=\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Applause_labels/\"\n",
    "\n",
    "applause_filenames=os.listdir(applause_labels_dir)\n",
    "\n",
    "\n",
    "applause_dict={}\n",
    "\n",
    "for filename in applause_filenames:\n",
    "    basename=filename.replace('.applause.csv','')\n",
    "    path=os.path.join(applause_labels_dir,filename)\n",
    "    range_table=[]\n",
    "    with open(path) as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for start,numeric_id,duration in spamreader:\n",
    "            if float(duration)>2.0:\n",
    "                if (float(start)-1.0) > 0:\n",
    "                    adjusted_start=float(start)-1.0\n",
    "                else:\n",
    "                    adjusted_start=float(start)\n",
    "                range_table.append([adjusted_start,float(start)+float(duration)])\n",
    "    applause_dict[basename]=range_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99.0, 103.0],\n",
       " [301.0, 305.0],\n",
       " [741.0, 745.0],\n",
       " [949.0, 954.0],\n",
       " [1522.0, 1526.0],\n",
       " [1591.0, 1599.0],\n",
       " [1684.0, 1688.0],\n",
       " [1696.0, 1703.0],\n",
       " [1725.0, 1738.0],\n",
       " [1753.0, 1770.0],\n",
       " [1796.0, 1801.0],\n",
       " [1907.0, 1942.0],\n",
       " [1949.0, 1957.0],\n",
       " [1962.0, 1970.0],\n",
       " [2720.0, 2734.0],\n",
       " [2747.0, 2751.0],\n",
       " [2754.0, 2765.0],\n",
       " [2799.0, 2830.0],\n",
       " [3237.0, 3244.0],\n",
       " [3318.0, 3329.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applause_dict['cpb-aacip-15-5m6251fq65__barcode349720_.h264']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_between(value,range_pair):\n",
    "    if float(range_pair[0]) < float(value) < float(range_pair[1]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def spans_overlap(range_1,range_2):\n",
    "    if is_between(range_2[0],range_1):\n",
    "        return True\n",
    "    elif is_between(range_2[1],range_1):\n",
    "        return True\n",
    "    elif is_between(range_1[0],range_2):\n",
    "        return True\n",
    "    elif is_between(range_1[1],range_2):\n",
    "        return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "range_1=[1725.0, 1738.0]\n",
    "range_2=[1727.0, 1728.0]\n",
    "range_3=[900.0, 901.0]\n",
    "\n",
    "print(spans_overlap(range_1,range_2))\n",
    "print(spans_overlap(range_2,range_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPB Unique Identifier (GUID)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "      <th>class ID</th>\n",
       "      <th>Timecode IN</th>\n",
       "      <th>Timecode OUT</th>\n",
       "      <th>Tag Duration</th>\n",
       "      <th>File Duration</th>\n",
       "      <th>SonyCi ID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178273</th>\n",
       "      <td>cpb-aacip/15-9w37kv75</td>\n",
       "      <td>Sound quality</td>\n",
       "      <td>audience clapping</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>1319.976</td>\n",
       "      <td>090d1475c56c45808fad6567b2f88b3d</td>\n",
       "      <td>cpb-aacip-15-9w37kv75__213877_</td>\n",
       "      <td>/Volumes/McLaughlin-6TB-1/Extended_Corpus/Gera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAPB Unique Identifier (GUID)           Type              Value  \\\n",
       "178273         cpb-aacip/15-9w37kv75  Sound quality  audience clapping   \n",
       "\n",
       "       class ID  Timecode IN  Timecode OUT  Tag Duration  File Duration  \\\n",
       "178273      NaN          223           225             2       1319.976   \n",
       "\n",
       "                               SonyCi ID                        Filename  \\\n",
       "178273  090d1475c56c45808fad6567b2f88b3d  cpb-aacip-15-9w37kv75__213877_   \n",
       "\n",
       "                                                 Pathname  \n",
       "178273  /Volumes/McLaughlin-6TB-1/Extended_Corpus/Gera...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading table of labeled 2-second audio segments\n",
    "\n",
    "aapb_metadata_all_split=pd.read_csv(\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/AAPB_ARLO_All_170414_2_sec_segs.csv\")\n",
    "aapb_metadata_all_split.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function for extracting speaker clips\n",
    "\n",
    "def extract_clips(x_table):\n",
    "    for unique_audio_path in [item for item in sorted(list(set(list(x_table['Pathname'])))) if str(item)!='nan']:\n",
    "        inputfile=unique_audio_path\n",
    "        if os.path.exists(inputfile):\n",
    "            if inputfile.lower()[-4:].lower() in ('.wav','.mp3','.mp4'):\n",
    "                wav_source=True\n",
    "                if inputfile.lower()[-4:]=='.mp4':     # Creates a temporary WAV\n",
    "                    wav_source=False                         # if input is MP4\n",
    "                    temp_filename=inputfile.split('/')[-1]+'_temp.wav'\n",
    "                    audio_path='/var/tmp/'+temp_filename   # Pathname for temp WAV\n",
    "                    subprocess.call(['ffmpeg', '-y', '-i', inputfile, audio_path]) # '-y' option overwrites existing file if present\n",
    "                else:\n",
    "                    audio_path=inputfile\n",
    "\n",
    "                song=None\n",
    "                from pydub import AudioSegment\n",
    "                \n",
    "                if inputfile[-4:].lower()=='.mp3':\n",
    "                    song = AudioSegment.from_mp3(audio_path)\n",
    "                else:\n",
    "                    song = AudioSegment.from_wav(audio_path)\n",
    "\n",
    "\n",
    "        for index, rowref in x_table[x_table['Pathname']==unique_audio_path].iterrows():\n",
    "            row=aapb_metadata_all_split.iloc[index] ## Ref to master split table\n",
    "            time_in=row['Timecode IN']\n",
    "            clip_duration=row['Tag Duration']\n",
    "            inputfile=row['Pathname']\n",
    "            basename=row['Filename']\n",
    "            dir_name=row['Value']\n",
    "\n",
    "            \n",
    "            try: os.mkdir(dir_name)\n",
    "            except: pass\n",
    "\n",
    "            applause_table = applause_dict[basename]\n",
    "            \n",
    "            contains_applause=False\n",
    "            \n",
    "            span_pair=[float(time_in),float(time_in)+float(clip_duration)]\n",
    "            \n",
    "            for row in applause_table:\n",
    "                if spans_overlap(row,span_pair):\n",
    "                    contains_applause=True\n",
    "            \n",
    "            if contains_applause==False:\n",
    "                from pydub import AudioSegment \n",
    "                start_msec = float(time_in) * 1000.0\n",
    "                duration_msec = float(clip_duration) * 1000\n",
    "                clip_pathname=basename+'.start_'+str(time_in)[:8]+'.dur_2s.wav'\n",
    "                if not os.path.exists(os.path.join(dir_name,clip_pathname)):\n",
    "                    clip_data = song[start_msec:start_msec+duration_msec]\n",
    "                    clip_data=clip_data.set_channels(1)\n",
    "                    clip_data.export(os.path.join(dir_name,clip_pathname), format=\"wav\")\n",
    "\n",
    "        try:\n",
    "            if wav_source==False:\n",
    "                os.remove(audio_path)\n",
    "        except: pass\n",
    "\n",
    "    print(\"*** All segments extracted! ***\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2692 clips available for Clinton, Bill\n"
     ]
    }
   ],
   "source": [
    "print(str(len(aapb_metadata_all_split[aapb_metadata_all_split['Value']==speaker]))+\" clips available for \"+speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2692\n",
      "*** All segments extracted! ***\n"
     ]
    }
   ],
   "source": [
    "##### Running the Random Clip Extractor #####\n",
    "\n",
    "\n",
    "num_clips=2692     ## number of 2-second clips desired\n",
    "\n",
    "x_table=aapb_metadata_all_split[aapb_metadata_all_split['Value']==speaker].sample(n=num_clips)\n",
    "\n",
    "########### skipping files in haystack ############\n",
    "haystack_files=['cpb-aacip-111-53wstzp5.h264', 'cpb-aacip-111-53wsv001.h264', 'cpb-aacip-111-569325x7.h264', 'cpb-aacip-189-12m6402b.h264', 'cpb-aacip-293-br8mc8rr8k__HUT00000045001_.h264', 'cpb-aacip-503-j96057dh5p__NHPR95198', 'cpb-aacip-503-s17sn01t72__NHPR95200']\n",
    "\n",
    "x_table=x_table[~x_table['Filename'].isin(haystack_files)]\n",
    "\n",
    "print(len(x_table))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extract_clips(x_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating ID string appended to each model's filename ##\n",
    "\n",
    "clip_count=len(os.listdir(speaker))\n",
    "\n",
    "model_id = '_'+last_name+'_UBM_'+str(clip_count)+'x2s'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Assembling UBM files\n",
    "\n",
    "os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')\n",
    "\n",
    "new_ubm_dir='UBM'+'_'+last_name\n",
    "\n",
    "\n",
    "try: os.mkdir(new_ubm_dir)\n",
    "except: pass\n",
    "\n",
    "ubm_source=\"/Volumes/U/AAPB_Corpus_May_2017/test_set_616_clips\"\n",
    "ubm_files=[item for item in os.listdir(ubm_source) if (speaker not in item)&('16000.wav' in item)]\n",
    "ubm_files=random.sample(ubm_files,60)\n",
    "for filename in ubm_files:\n",
    "    shutil.copy(os.path.join(ubm_source,filename),new_ubm_dir)\n",
    "\n",
    "    \n",
    "ubm_source=\"/Volumes/U/AAPB_Corpus_May_2017/PennSound_UBM_for_Creeley_full_clips_16000\"\n",
    "ubm_files=[item for item in os.listdir(ubm_source) if (speaker not in item)&('.wav' in item)]\n",
    "ubm_files=random.sample(ubm_files,60)\n",
    "for filename in ubm_files:\n",
    "    shutil.copy(os.path.join(ubm_source,filename),new_ubm_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complexity ratio: 41.4 x realtime\n",
      "Feature extraction complexity ratio: 44.1 x realtime\n",
      "Number of training experiments changed to 50 due to high number of samples\n",
      "Number of training experiments changed to 10 due to high number of samples\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 10 of 10\n",
      "\t\tUBM_Clinton_Bill\t\t\tClinton, Bill\t\tOVERALL\n",
      "\tC \tPRE\tREC\tF1 \tPRE\tREC\tF1 \tACC\tF1\n",
      "\t0.001 \t50.0\t0.0\t0.0 \t95.7\t100.0\t97.8 \t95.7\t48.9\n",
      "\t0.010 \t90.0\t7.5\t13.8 \t96.0\t100.0\t98.0 \t96.0\t55.9\n",
      "\t0.500 \t75.5\t59.2\t66.4 \t98.2\t99.1\t98.7 \t97.4\t82.5\n",
      "\t1.000 \t79.1\t56.7\t66.0 \t98.1\t99.3\t98.7 \t97.5\t82.4 \t best Acc\n",
      "\t5.000 \t69.4\t64.2\t66.7 \t98.4\t98.7\t98.6 \t97.2\t82.6 \t best F1\n",
      "\t10.000 \t65.8\t60.8\t63.2 \t98.3\t98.6\t98.4 \t97.0\t80.8\n",
      "Confusion Matrix:\n",
      "\tUBM \tCli\n",
      "UBM \t2.4 \t1.9\n",
      "Cli \t0.6 \t95.1\n",
      "Selected params: 1.00000\n",
      "done\n",
      "798.139309883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Train Model\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "#print(timeit.default_timer() - tic)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')\n",
    "\n",
    "\n",
    "aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"svm\", \"svm\"+model_id, False)\n",
    "print(\"done\")\n",
    "print(timeit.default_timer() - tic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3024674177\n"
     ]
    }
   ],
   "source": [
    "print(timeit.default_timer() - tic)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Other classifiers ##\n",
    "\n",
    "#os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')\n",
    "\n",
    "#tic=timeit.default_timer()\n",
    "#aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"gradientboosting\", \"gradientboosting\"+model_id, False)\n",
    "#print(\"done\")\n",
    "#print(timeit.default_timer() - tic)\n",
    "#tic=timeit.default_timer()\n",
    "#aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"extratrees\", \"extratrees\"+model_id, False)\n",
    "#print(\"done\")\n",
    "#print(timeit.default_timer() - tic)\n",
    "#tic=timeit.default_timer()\n",
    "#aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"randomforest\", \"randomforest\"+model_id, False)\n",
    "#print(\"done\")\n",
    "#print(timeit.default_timer() - tic)\n",
    "#tic=timeit.default_timer()\n",
    "#aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"knn\", \"knn\"+model_id, False)\n",
    "#print(\"done\")\n",
    "#print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3077500502\n"
     ]
    }
   ],
   "source": [
    "print(timeit.default_timer() - tic)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes list of 1-second segments classified as speaker (1.0) or \n",
    "# non-speaker (0.0) and returns list of 2-tuples specifying speaker ranges.\n",
    "# Add 1 to 2nd speaker in each 2-tuple for inclusive time span.\n",
    "def seconds_list_to_ranges(seconds_list): \n",
    "    ranges = []                \n",
    "    for k, g in groupby(enumerate(seconds_list), lambda (i,x):i-x):\n",
    "        group = map(itemgetter(1), g)\n",
    "        ranges.append((group[0], group[-1]))\n",
    "    return ranges\n",
    "\n",
    "\n",
    "# Displays specified audio segment in Jupyter window using IPython.display\n",
    "def display_clip(wav_path,start_time,end_time):\n",
    "    track_data = AudioSegment.from_wav(file=wav_path)\n",
    "    track_data = track_data.set_channels(1)\n",
    "    bit_depth = track_data.sample_width * 8\n",
    "    clip_data = track_data[int(1000*start_time):int(1000*end_time)]\n",
    "    array_type = get_array_type(bit_depth)\n",
    "    numeric_array = array.array(array_type, clip_data._data)\n",
    "    display(Audio(numeric_array, rate=track_data.frame_rate))\n",
    "\n",
    "# Classifies audio at 1-second resolution, plots results if speaker found, \n",
    "# and returns speaker ranges as list of 2-tuples.\n",
    "# Add 1 to 2nd speaker in each 2-tuple for inclusive time span.\n",
    "\n",
    "def find_speaker(audio_path,classifier_model_path):\n",
    "    classifier_model_name = classifier_model_path.split('/')[-1]\n",
    "    classifier_model_type = classifier_model_name.split('_')[0].lower() # assuming model file begins svm_etc\n",
    "    \n",
    "    buffer_secs=0\n",
    "    is_mp3=False\n",
    "    if audio_path.lower()[-4:] in ['.mp3','.mp4','.wav']:    # Creates a temporary WAV\n",
    "        is_mp3=True                        # if input is MP3\n",
    "        random.seed(audio_path)\n",
    "        wav_path='/var/tmp/'+str(random.random())+'_temp.wav' # Filename for temp WAV is a random float\n",
    "        subprocess.call(['ffmpeg', '-i', audio_path, '-y', '-ar', '16000', '-ac', '1', '-af', \"volume=0.99,highpass=f=150, lowpass=f=5000\",  wav_path]) # '-y' option overwrites existing file if present\n",
    "    else:\n",
    "        wav_path=audio_path\n",
    "    print(wav_path)\n",
    "    output, classesAll, acc, CM = aS.mtFileClassification(wav_path, classifier_model_path, classifier_model_type) #or replace with 'svm' etc. as needed\n",
    "    output = list(output)\n",
    "    counter=0\n",
    "    speaker_secs=[]\n",
    "    for speaker in output:\n",
    "        if speaker>0.0:\n",
    "            speaker_secs.append(counter)\n",
    "        counter+=1\n",
    "    speaker_ranges=seconds_list_to_ranges(speaker_secs)\n",
    "    #if len(speaker_ranges)>0:\n",
    "    #    print speaker_ranges\n",
    "    #    print '\\n'\n",
    "    #    pd.Series(output).plot()                      # uncomment to display plot and audio clips in notebook\n",
    "    #    plt.show()\n",
    "    #for pair in speaker_ranges:\n",
    "    #    print pair\n",
    "    #    display_clip(wav_path,pair[0],pair[1]+1)\n",
    "    if is_mp3==True:\n",
    "        os.remove(wav_path)\n",
    "    outputfile=audio_path.split('/')[-1][:-4]+\"_\"+classifier_model_name+\".csv\"\n",
    "    with open(outputfile, 'w') as csv_fo:\n",
    "        speaker_ranges_expanded=[(start,1,end-start+1) for start,end in speaker_ranges]\n",
    "        csv_writer = csv.writer(csv_fo)\n",
    "        csv_writer.writerows(speaker_ranges_expanded)\n",
    "    print(outputfile)\n",
    "    return speaker_ranges_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill/cpb-aacip-503-j96057dh5p__NHPR95198.16000.wav', '/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill/cpb-aacip-503-s17sn01t72__NHPR95200.16000.wav', '/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill/cpb-aacip-293-br8mc8rr8k__HUT00000045001_.h264.16000.wav', '/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill/cpb-aacip-111-53wsv001.h264.16000.wav', '/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill/cpb-aacip-111-53wstzp5.h264.16000.wav', '/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill/cpb-aacip-189-12m6402b.h264.16000.wav', '/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill/cpb-aacip-111-569325x7.h264.16000.wav']\n"
     ]
    }
   ],
   "source": [
    "test_dir=\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/YouTube_corpus/\"+speaker\n",
    "\n",
    "test_dir=\"/Volumes/U/AAPB_Corpus_May_2017/AAPB_Test_Haystack_Clinton_Bill\"\n",
    "\n",
    "test_files=[os.path.join(test_dir,item) for item in os.listdir(test_dir) \\\n",
    "            if (\".DS_Store\" not in item)&(item[-4:].lower() in ('.mp4','.mp3','.wav'))]\n",
    "\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_model_paths=[\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips/\"+\"svm\"+model_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/tmp/0.0705723580741_temp.wav\n",
      "cpb-aacip-503-j96057dh5p__NHPR95198.16000_svm_Clinton_Bill_UBM_2684x2s.csv\n",
      "32.6739301682\n",
      "/var/tmp/0.148064958265_temp.wav\n",
      "cpb-aacip-503-s17sn01t72__NHPR95200.16000_svm_Clinton_Bill_UBM_2684x2s.csv\n",
      "996.240266085\n",
      "/var/tmp/0.963435849973_temp.wav\n",
      "cpb-aacip-293-br8mc8rr8k__HUT00000045001_.h264.16000_svm_Clinton_Bill_UBM_2684x2s.csv\n",
      "1141.51437998\n",
      "/var/tmp/0.914327820858_temp.wav\n",
      "cpb-aacip-111-53wsv001.h264.16000_svm_Clinton_Bill_UBM_2684x2s.csv\n",
      "1596.13094616\n",
      "/var/tmp/0.455338151996_temp.wav\n",
      "cpb-aacip-111-53wstzp5.h264.16000_svm_Clinton_Bill_UBM_2684x2s.csv\n",
      "1674.11130118\n",
      "/var/tmp/0.357730644585_temp.wav\n",
      "cpb-aacip-189-12m6402b.h264.16000_svm_Clinton_Bill_UBM_2684x2s.csv\n",
      "1681.94317317\n",
      "/var/tmp/0.679796493049_temp.wav\n",
      "cpb-aacip-111-569325x7.h264.16000_svm_Clinton_Bill_UBM_2684x2s.csv\n",
      "1750.07323813\n"
     ]
    }
   ],
   "source": [
    "# Example speaker search\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "#print(timeit.default_timer() - tic)\n",
    "\n",
    "#audio_path=test_files[2]\n",
    "\n",
    "for classifier_model_path in classifier_model_paths:\n",
    "    for audio_path in test_files:\n",
    "        try: \n",
    "            dd=find_speaker(audio_path,classifier_model_path)\n",
    "            print(timeit.default_timer() - tic)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750.08189106\n"
     ]
    }
   ],
   "source": [
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
