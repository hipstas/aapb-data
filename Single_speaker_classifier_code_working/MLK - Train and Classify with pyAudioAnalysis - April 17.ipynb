{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import array\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from pyAudioAnalysis import audioTrainTest as aT\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from IPython.display import display, Audio\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import get_array_type\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King, Martin Luther\n",
      "King\n"
     ]
    }
   ],
   "source": [
    "speaker=\"King, Martin Luther\"\n",
    "\n",
    "last_name = speaker.split(', ')[0]\n",
    "\n",
    "print(speaker)\n",
    "print(last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading dictionary of applause classification values\n",
    "\n",
    "applause_labels_dir=\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Applause_labels/\"\n",
    "\n",
    "applause_filenames=os.listdir(applause_labels_dir)\n",
    "\n",
    "\n",
    "applause_dict={}\n",
    "\n",
    "for filename in applause_filenames:\n",
    "    basename=filename.replace('.applause.csv','')\n",
    "    path=os.path.join(applause_labels_dir,filename)\n",
    "    range_table=[]\n",
    "    with open(path) as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for start,numeric_id,duration in spamreader:\n",
    "            if float(duration)>2.0:\n",
    "                if (float(start)-1.0) > 0:\n",
    "                    adjusted_start=float(start)-1.0\n",
    "                else:\n",
    "                    adjusted_start=float(start)\n",
    "                range_table.append([adjusted_start,float(start)+float(duration)])\n",
    "    applause_dict[basename]=range_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99.0, 103.0],\n",
       " [301.0, 305.0],\n",
       " [741.0, 745.0],\n",
       " [949.0, 954.0],\n",
       " [1522.0, 1526.0],\n",
       " [1591.0, 1599.0],\n",
       " [1684.0, 1688.0],\n",
       " [1696.0, 1703.0],\n",
       " [1725.0, 1738.0],\n",
       " [1753.0, 1770.0],\n",
       " [1796.0, 1801.0],\n",
       " [1907.0, 1942.0],\n",
       " [1949.0, 1957.0],\n",
       " [1962.0, 1970.0],\n",
       " [2720.0, 2734.0],\n",
       " [2747.0, 2751.0],\n",
       " [2754.0, 2765.0],\n",
       " [2799.0, 2830.0],\n",
       " [3237.0, 3244.0],\n",
       " [3318.0, 3329.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applause_dict['cpb-aacip-15-5m6251fq65__barcode349720_.h264']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_between(value,range_pair):\n",
    "    if float(range_pair[0]) < float(value) < float(range_pair[1]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def spans_overlap(range_1,range_2):\n",
    "    if is_between(range_2[0],range_1):\n",
    "        return True\n",
    "    elif is_between(range_2[1],range_1):\n",
    "        return True\n",
    "    elif is_between(range_1[0],range_2):\n",
    "        return True\n",
    "    elif is_between(range_1[1],range_2):\n",
    "        return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "range_1=[1725.0, 1738.0]\n",
    "range_2=[1727.0, 1728.0]\n",
    "range_3=[900.0, 901.0]\n",
    "\n",
    "print(spans_overlap(range_1,range_2))\n",
    "print(spans_overlap(range_2,range_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPB Unique Identifier (GUID)</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "      <th>class ID</th>\n",
       "      <th>Timecode IN</th>\n",
       "      <th>Timecode OUT</th>\n",
       "      <th>Tag Duration</th>\n",
       "      <th>File Duration</th>\n",
       "      <th>SonyCi ID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178273</th>\n",
       "      <td>cpb-aacip/15-9w37kv75</td>\n",
       "      <td>Sound quality</td>\n",
       "      <td>audience clapping</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>1319.976</td>\n",
       "      <td>090d1475c56c45808fad6567b2f88b3d</td>\n",
       "      <td>cpb-aacip-15-9w37kv75__213877_</td>\n",
       "      <td>/Volumes/McLaughlin-6TB-1/Extended_Corpus/Gera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AAPB Unique Identifier (GUID)           Type              Value  \\\n",
       "178273         cpb-aacip/15-9w37kv75  Sound quality  audience clapping   \n",
       "\n",
       "       class ID  Timecode IN  Timecode OUT  Tag Duration  File Duration  \\\n",
       "178273      NaN          223           225             2       1319.976   \n",
       "\n",
       "                               SonyCi ID                        Filename  \\\n",
       "178273  090d1475c56c45808fad6567b2f88b3d  cpb-aacip-15-9w37kv75__213877_   \n",
       "\n",
       "                                                 Pathname  \n",
       "178273  /Volumes/McLaughlin-6TB-1/Extended_Corpus/Gera...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading table of labeled 2-second audio segments\n",
    "\n",
    "aapb_metadata_all_split=pd.read_csv(\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/AAPB_ARLO_All_170414_2_sec_segs.csv\")\n",
    "aapb_metadata_all_split.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function for extracting speaker clips\n",
    "\n",
    "def extract_clips(x_table):\n",
    "    for unique_audio_path in sorted(list(set(list(x_table['Pathname'])))):\n",
    "        inputfile=unique_audio_path\n",
    "        if os.path.exists(inputfile):\n",
    "            if inputfile.lower()[-4:].lower() in ('.wav','.mp3','.mp4'):\n",
    "                wav_source=True\n",
    "                if inputfile.lower()[-4:]=='.mp4':     # Creates a temporary WAV\n",
    "                    wav_source=False                         # if input is MP4\n",
    "                    temp_filename=inputfile.split('/')[-1]+'_temp.wav'\n",
    "                    audio_path='/var/tmp/'+temp_filename   # Pathname for temp WAV\n",
    "                    subprocess.call(['ffmpeg', '-y', '-i', inputfile, audio_path]) # '-y' option overwrites existing file if present\n",
    "                else:\n",
    "                    audio_path=inputfile\n",
    "\n",
    "                song=None\n",
    "                from pydub import AudioSegment\n",
    "                \n",
    "                if inputfile[-4:].lower()=='.mp3':\n",
    "                    song = AudioSegment.from_mp3(audio_path)\n",
    "                else:\n",
    "                    song = AudioSegment.from_wav(audio_path)\n",
    "\n",
    "\n",
    "        for index, rowref in x_table[x_table['Pathname']==unique_audio_path].iterrows():\n",
    "            row=aapb_metadata_all_split.iloc[index] ## Ref to master split table\n",
    "            time_in=row['Timecode IN']\n",
    "            clip_duration=row['Tag Duration']\n",
    "            inputfile=row['Pathname']\n",
    "            basename=row['Filename']\n",
    "            dir_name=row['Value']\n",
    "\n",
    "            \n",
    "            try: os.mkdir(dir_name)\n",
    "            except: pass\n",
    "\n",
    "            applause_table = applause_dict[basename]\n",
    "            \n",
    "            contains_applause=False\n",
    "            \n",
    "            span_pair=[float(time_in),float(time_in)+float(clip_duration)]\n",
    "            \n",
    "            for row in applause_table:\n",
    "                if spans_overlap(row,span_pair):\n",
    "                    contains_applause=True\n",
    "            \n",
    "            if contains_applause==False:\n",
    "                from pydub import AudioSegment \n",
    "                start_msec = float(time_in) * 1000.0\n",
    "                duration_msec = float(clip_duration) * 1000\n",
    "                clip_pathname=basename+'.start_'+str(time_in)[:8]+'.dur_2s.wav'\n",
    "                if not os.path.exists(os.path.join(dir_name,clip_pathname)):\n",
    "                    clip_data = song[start_msec:start_msec+duration_msec]\n",
    "                    clip_data=clip_data.set_channels(1)\n",
    "                    clip_data.export(os.path.join(dir_name,clip_pathname), format=\"wav\")\n",
    "\n",
    "        try:\n",
    "            if wav_source==False:\n",
    "                os.remove(audio_path)\n",
    "        except: pass\n",
    "\n",
    "    print(\"*** All segments extracted! ***\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21179 clips available for King, Martin Luther\n"
     ]
    }
   ],
   "source": [
    "print(str(len(aapb_metadata_all_split[aapb_metadata_all_split['Value']==speaker]))+\" clips available for \"+speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All segments extracted! ***\n"
     ]
    }
   ],
   "source": [
    "##### Running the Random Clip Extractor #####\n",
    "\n",
    "\n",
    "num_clips=3000     ## number of 2-second clips desired\n",
    "\n",
    "x_table=aapb_metadata_all_split[aapb_metadata_all_split['Value']==speaker].sample(n=num_clips)\n",
    "\n",
    "extract_clips(x_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating ID string appended to each model's filename\n",
    "\n",
    "clip_count=len(os.listdir(speaker))\n",
    "\n",
    "model_id = '_'+last_name+'_UBM_'+str(clip_count)+'x2s'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Assembling UBM files\n",
    "\n",
    "os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')\n",
    "\n",
    "new_ubm_dir='UBM'+'_'+last_name\n",
    "\n",
    "\n",
    "try: os.mkdir(new_ubm_dir)\n",
    "except: pass\n",
    "\n",
    "ubm_source=\"/Volumes/U/AAPB_Corpus_May_2017/test_set_616_clips\"\n",
    "ubm_files=[item for item in os.listdir(ubm_source) if (speaker not in item)&('16000.wav' in item)]\n",
    "ubm_files=random.sample(ubm_files,60)\n",
    "for filename in ubm_files:\n",
    "    shutil.copy(os.path.join(ubm_source,filename),new_ubm_dir)\n",
    "\n",
    "    \n",
    "ubm_source=\"/Volumes/U/AAPB_Corpus_May_2017/PennSound_UBM_for_Creeley_full_clips_16000\"\n",
    "ubm_files=[item for item in os.listdir(ubm_source) if (speaker not in item)&('.wav' in item)]\n",
    "ubm_files=random.sample(ubm_files,60)\n",
    "for filename in ubm_files:\n",
    "    shutil.copy(os.path.join(ubm_source,filename),new_ubm_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complexity ratio: 68.8 x realtime\n",
      "Feature extraction complexity ratio: 76.4 x realtime\n",
      "Number of training experiments changed to 50 due to high number of samples\n",
      "Number of training experiments changed to 10 due to high number of samples\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 0.00100 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 0.01000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 0.50000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 1.00000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 5.00000 - Classifier Evaluation Experiment 10 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 1 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 2 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 3 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 4 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 5 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 6 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 7 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 8 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 9 of 10\n",
      "Param = 10.00000 - Classifier Evaluation Experiment 10 of 10\n",
      "\t\tUBM_King\t\t\tKing, Martin Luther\t\tOVERALL\n",
      "\tC \tPRE\tREC\tF1 \tPRE\tREC\tF1 \tACC\tF1\n",
      "\t0.001 \t50.0\t0.0\t0.0 \t96.1\t100.0\t98.0 \t96.1\t49.0\n",
      "\t0.010 \t89.2\t27.5\t42.0 \t97.2\t99.9\t98.5 \t97.1\t70.3\n",
      "\t0.500 \t82.3\t65.8\t73.1 \t98.6\t99.4\t99.0 \t98.1\t86.1\n",
      "\t1.000 \t78.2\t71.7\t74.8 \t98.9\t99.2\t99.0 \t98.1\t86.9\n",
      "\t5.000 \t81.9\t71.7\t76.4 \t98.9\t99.4\t99.1 \t98.3\t87.8 \t best F1 \t best Acc\n",
      "\t10.000 \t81.7\t70.8\t75.9 \t98.8\t99.4\t99.1 \t98.3\t87.5\n",
      "Confusion Matrix:\n",
      "\tUBM \tKin\n",
      "UBM \t2.8 \t1.1\n",
      "Kin \t0.6 \t95.5\n",
      "Selected params: 5.00000\n",
      "done\n",
      "535.522907019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Train Model\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "#print(timeit.default_timer() - tic)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')\n",
    "\n",
    "\n",
    "aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"svm\", \"svm\"+model_id, False)\n",
    "print(\"done\")\n",
    "print(timeit.default_timer() - tic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.92548398177\n"
     ]
    }
   ],
   "source": [
    "print(timeit.default_timer() - tic)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Other classifiers\n",
    "\n",
    "os.chdir('/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips')\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"gradientboosting\", \"gradientboosting\"+model_id, False)\n",
    "print(\"done\")\n",
    "print(timeit.default_timer() - tic)\n",
    "tic=timeit.default_timer()\n",
    "aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"extratrees\", \"extratrees\"+model_id, False)\n",
    "print(\"done\")\n",
    "print(timeit.default_timer() - tic)\n",
    "tic=timeit.default_timer()\n",
    "aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"randomforest\", \"randomforest\"+model_id, False)\n",
    "print(\"done\")\n",
    "print(timeit.default_timer() - tic)\n",
    "tic=timeit.default_timer()\n",
    "aT.featureAndTrain([new_ubm_dir,speaker], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, \"knn\", \"knn\"+model_id, False)\n",
    "print(\"done\")\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(timeit.default_timer() - tic)/60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes list of 1-second segments classified as speaker (1.0) or \n",
    "# non-speaker (0.0) and returns list of 2-tuples specifying speaker ranges.\n",
    "# Add 1 to 2nd speaker in each 2-tuple for inclusive time span.\n",
    "def seconds_list_to_ranges(seconds_list): \n",
    "    ranges = []                \n",
    "    for k, g in groupby(enumerate(seconds_list), lambda (i,x):i-x):\n",
    "        group = map(itemgetter(1), g)\n",
    "        ranges.append((group[0], group[-1]))\n",
    "    return ranges\n",
    "\n",
    "\n",
    "# Displays specified audio segment in Jupyter window using IPython.display\n",
    "def display_clip(wav_path,start_time,end_time):\n",
    "    track_data = AudioSegment.from_wav(file=wav_path)\n",
    "    track_data = track_data.set_channels(1)\n",
    "    bit_depth = track_data.sample_width * 8\n",
    "    clip_data = track_data[int(1000*start_time):int(1000*end_time)]\n",
    "    array_type = get_array_type(bit_depth)\n",
    "    numeric_array = array.array(array_type, clip_data._data)\n",
    "    display(Audio(numeric_array, rate=track_data.frame_rate))\n",
    "\n",
    "# Classifies audio at 1-second resolution, plots results if speaker found, \n",
    "# and returns speaker ranges as list of 2-tuples.\n",
    "# Add 1 to 2nd speaker in each 2-tuple for inclusive time span.\n",
    "\n",
    "\n",
    "\n",
    "def smooth(x,window_len=10,window='hanning'):\n",
    "        if x.ndim != 1:\n",
    "                raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "        if x.size < window_len:\n",
    "                raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "        if window_len<3:\n",
    "                return x\n",
    "        if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "        s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:  \n",
    "                w=eval('np.'+window+'(window_len)')\n",
    "        y=np.convolve(w/w.sum(),s,mode='same')\n",
    "        return y[window_len:-window_len+1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_speaker(audio_path,classifier_model_path):\n",
    "    classifier_model_name = classifier_model_path.split('/')[-1]\n",
    "    classifier_model_type = classifier_model_name.split('_')[0].lower() # assuming model file begins svm_etc\n",
    "    \n",
    "    buffer_secs=0\n",
    "    is_mp3=False\n",
    "    if audio_path.lower()[-4:] in ['.mp3','.mp4','.wav']:    # Creates a temporary WAV\n",
    "        is_mp3=True                        # if input is MP3\n",
    "        random.seed(audio_path)\n",
    "        wav_path='/var/tmp/'+str(random.random())+'_temp.wav' # Filename for temp WAV is a random float\n",
    "        subprocess.call(['ffmpeg', '-i', audio_path, '-y', '-ar', '16000', '-ac', '1', '-af', \"volume=0.99,highpass=f=150, lowpass=f=5000\",  wav_path]) # '-y' option overwrites existing file if present\n",
    "    else:\n",
    "        wav_path=audio_path\n",
    "    print(wav_path)\n",
    "    output, classesAll, acc, CM = aS.mtFileClassification(wav_path, classifier_model_path, classifier_model_type) #or replace with 'svm' etc. as needed\n",
    "    output = list(output)\n",
    "    counter=0\n",
    "    speaker_secs=[]\n",
    "    for speaker in output:\n",
    "        if speaker>0.0:\n",
    "            speaker_secs.append(counter)\n",
    "        counter+=1\n",
    "    speaker_ranges=seconds_list_to_ranges(speaker_secs)\n",
    "    #if len(speaker_ranges)>0:\n",
    "    #    print speaker_ranges\n",
    "    #    print '\\n'\n",
    "    #    pd.Series(output).plot()                      # uncomment for A/V feedback in notebook\n",
    "    #    plt.show()\n",
    "    #for pair in speaker_ranges:\n",
    "    #    print pair\n",
    "    #    display_clip(wav_path,pair[0],pair[1]+1)\n",
    "    if is_mp3==True:\n",
    "        os.remove(wav_path)\n",
    "    ##outputfile=audio_path[:-4]+\"_\"+classifier_model_name+\".csv\"\n",
    "    ##with open(outputfile, 'w') as csv_fo:\n",
    "    ##    speaker_ranges_expanded=[(start,1,end-start+1) for start,end in speaker_ranges]\n",
    "    ##    csv_writer = csv.writer(csv_fo)\n",
    "    ##    csv_writer.writerows(speaker_ranges_expanded)\n",
    "    #print(outputfile)\n",
    "    \n",
    "    ## Smooth version\n",
    "    output_smooth_temp = list(smooth(np.array(output),window_len=10))\n",
    "    output_smooth=[]\n",
    "    for item in output_smooth_temp:\n",
    "        output_smooth.append(round(item))\n",
    "    counter=0\n",
    "    speaker_secs=[]\n",
    "    for segment in output_smooth:\n",
    "        if segment>0.0:\n",
    "            speaker_secs.append(counter)\n",
    "        counter+=1\n",
    "    csv_smooth_pathname=audio_path[:-4]+\"_\"+classifier_model_name+\"_smooth10.csv\"\n",
    "    speaker_ranges = seconds_list_to_ranges(speaker_secs)\n",
    "    with open(csv_smooth_pathname, 'w') as csv_fo:\n",
    "        speaker_ranges_expanded=[(start,1,end-start+1) for start,end in speaker_ranges]\n",
    "        csv_writer = csv.writer(csv_fo)\n",
    "        csv_writer.writerows(speaker_ranges_expanded)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #return speaker_ranges_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-15-9gm81p0j__256757_.16000.wav',\n",
       " '/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-15-93j39132__256755_.16000.wav',\n",
       " '/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-15-97940t7x__111486_.16000.wav',\n",
       " '/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-28-319s17sx3t__PRA_AAPP_BB1460_Martin_Luther_King_at_Santa_Rita_.16000.wav',\n",
       " '/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-28-sb3ws8j14c__PRA_AAPP_BB5411_In_memory_of_Martin_Luther_King_Jr_.16000.wav',\n",
       " '/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-41-15bcch5q.h264.16000.wav',\n",
       " '/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-60-859cnz1m.h264.16000.wav',\n",
       " '/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King/cpb-aacip-78-07gqp4f8.h264.16000.wav']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_path=\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/YouTube_corpus/\"+speaker\n",
    "\n",
    "\n",
    "\n",
    "yt_path=\"/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_King\"\n",
    "\n",
    "\n",
    "test_files=[os.path.join(yt_path,item) for item in os.listdir(yt_path) if (\".DS_Store\" not in item)&(item[0]!='.')&(item[-4:].lower() in ('.mp4','.mp3','.wav'))]\n",
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_model_paths=[\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips/\"+\"svm\"+model_id]\n",
    "\n",
    "#classifier_model_path=\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips/randomforest_Baldwin_UBM_564x2s\",\\\n",
    "\n",
    "#classifier_model_path=\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips/svm_Baldwin_UBM_564x2s\"\n",
    "\n",
    "#test_files=[\\\n",
    "#'/Users/mclaugh/Desktop/WGBH_Youtube_tests/Malcolm X - Debate with James Baldwin - September 5, 1963--JIp9_IIV3s.mp4',\\\n",
    "#'/Volumes/McLaughlin-6TB-1/Extended_Corpus/James_Baldwin/cpb-aacip-75-48sbchq4.h264.mp4',\\\n",
    "#'/Users/mclaugh/Desktop/WGBH_Youtube_tests/Julia Child makes an omelet-RThnq3-d6PY.wav',\\\n",
    "#'/Volumes/McLaughlin-6TB-1/Extended_Corpus/James_Baldwin/cpb-aacip-15-719kdkmx.h264.mp4',\\\n",
    "#'/Volumes/McLaughlin-6TB-1/Extended_Corpus/James_Baldwin/cpb-aacip-28-n872v2ct06__PRA_AAPP_BB0838_Baldwin_at_the_Masonic_Temple_.mp3'\\\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/tmp/0.174452166875_temp.wav\n",
      "369.65973711\n",
      "/var/tmp/0.627030026127_temp.wav\n",
      "479.527198076\n",
      "/var/tmp/0.161222987987_temp.wav\n",
      "526.906942129\n",
      "/var/tmp/0.944367550243_temp.wav\n",
      "602.545544147\n",
      "/var/tmp/0.521676754898_temp.wav\n",
      "962.523350954\n",
      "/var/tmp/0.241668287024_temp.wav\n",
      "978.997881174\n",
      "/var/tmp/0.686229415619_temp.wav\n",
      "1032.24948096\n",
      "/var/tmp/0.403893735769_temp.wav\n",
      "1141.61834502\n"
     ]
    }
   ],
   "source": [
    "# Example speaker search\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "#print(timeit.default_timer() - tic)\n",
    "\n",
    "#audio_path=test_files[2]\n",
    "\n",
    "for classifier_model_path in classifier_model_paths:\n",
    "    for audio_path in test_files:\n",
    "        try: \n",
    "            dd=find_speaker(audio_path,classifier_model_path)\n",
    "            print(timeit.default_timer() - tic)\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141.62530804\n"
     ]
    }
   ],
   "source": [
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
